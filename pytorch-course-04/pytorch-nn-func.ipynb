{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## torch.nn.Linear(in_features, out_features, bias=True)\n",
    "\n",
    "对输入数据做线性变换: $y = Ax + b$\n",
    "\n",
    "### 参数\n",
    "\n",
    "- in_features: 每个输入样本的大小\n",
    "- out_features: 每个输出样本的大小\n",
    "- bias: 若设置为 `False` , 这层不会学习偏置. 默认值: `True`\n",
    "\n",
    "### 形状\n",
    "\n",
    "- 输入: $(N,in\\_features)$\n",
    "- 输出: $(N,out\\_features)$\n",
    "\n",
    "### 变量\n",
    "\n",
    "- weight: 形状为 $(out\\_features \\times in\\_features)$ 的模块中可学习的权值\n",
    "- bias: 形状为 $(out\\_features)$ 的模块中可学习的偏置"
   ],
   "id": "30aa5a20f641364"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T03:30:15.993469Z",
     "start_time": "2024-07-18T03:30:15.982209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# 定义一个线性变换函数\n",
    "# 这里定义的是 : y = a1*x1 + a2*x2 + b \n",
    "# 写成矩阵的形式是 : y = AX + b\n",
    "linear_func = nn.Linear(2, 1)\n",
    "\n",
    "# 创建数据\n",
    "data = torch.tensor(data = [1.,2.], requires_grad = True)\n",
    "print('weight:',linear_func.weight)\n",
    "print('bias:',linear_func.bias)\n",
    "print('result:',linear_func(data))\n",
    "\n",
    "# 用于验证计算结果的线性函数\n",
    "def cul_linear_func(weight, bias, data):\n",
    "    return torch.matmul(weight,data) + bias\n",
    "\n",
    "# 验证计算结果\n",
    "print(\"AX + b :\",cul_linear_func(linear_func.weight, linear_func.bias, data))"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight: Parameter containing:\n",
      "tensor([[ 0.4176, -0.6099]], requires_grad=True)\n",
      "bias: Parameter containing:\n",
      "tensor([0.2748], requires_grad=True)\n",
      "result: tensor([-0.5274], grad_fn=<ViewBackward0>)\n",
      "AX + b : tensor([-0.5274], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## torch.nn.Sequential(* args) \n",
    "\n",
    "一个时序容器。`Modules` 会以他们传入的顺序被添加到容器中。当然，也可以传入一个 `OrderedDict`。\n",
    "\n",
    "为了更容易的理解如何使用Sequential, 下面给出了一个例子:\n",
    "```python\n",
    "# Example of using Sequential\n",
    "model = nn.Sequential(\n",
    "          nn.Conv2d(1,20,5),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(20,64,5),\n",
    "          nn.ReLU()\n",
    "        )\n",
    "\n",
    "# Example of using Sequential with OrderedDict\n",
    "model = nn.Sequential(OrderedDict([\n",
    "          ('conv1', nn.Conv2d(1,20,5)),\n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('conv2', nn.Conv2d(20,64,5)),\n",
    "          ('relu2', nn.ReLU())\n",
    "        ]))\n",
    "```"
   ],
   "id": "b8396d6c967e5edb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 定义一个序列神经网络\n",
    "net = nn.Sequential(nn.Linear(2, 1))\n",
    "print('net:',net)"
   ],
   "id": "68e61159ee202391"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
